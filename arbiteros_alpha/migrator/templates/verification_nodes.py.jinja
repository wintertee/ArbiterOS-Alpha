"""{{ domain }}-specific verification nodes for ArbiterOS governance.

This module provides verification nodes that must be executed BEFORE high-risk
operations. Verification nodes implement the NormativeCore.VERIFY instruction
and provide safety checks, validation, and approval mechanisms.

Safety Pattern: HIGH_RISK_NODE cannot execute until VERIFY node approves.

Generated by ArbiterOS Migration Tool.
"""

import logging
from typing import Any, Dict, Optional
from dataclasses import dataclass

from arbiteros_alpha.instructions import NormativeCore

logger = logging.getLogger(__name__)


@dataclass
class VerificationResult:
    """Result of a verification check.
    
    Attributes:
        approved: Whether the operation is approved to proceed.
        confidence: Confidence in the verification decision (0.0-1.0).
        risk_level: Assessed risk level (0.0-1.0).
        reason: Human-readable explanation of the decision.
        requires_human_review: Whether human intervention is needed.
        validation_errors: List of specific validation failures.
    """
    approved: bool
    confidence: float
    risk_level: float
    reason: str
    requires_human_review: bool = False
    validation_errors: list = None
    
    def __post_init__(self):
        if self.validation_errors is None:
            self.validation_errors = []
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for state updates."""
        return {
            "verified": self.approved,
            "verification_confidence": self.confidence,
            "verification_risk_level": self.risk_level,
            "verification_reason": self.reason,
            "requires_human_review": self.requires_human_review,
            "validation_errors": self.validation_errors,
        }


class VerificationConfig:
    """Configuration for verification behavior.
    
    Attributes:
        max_risk_threshold: Maximum allowed risk level (default: 0.8).
        min_confidence_threshold: Minimum required confidence (default: 0.6).
        require_explicit_approval: Whether explicit 'approved' flag is required.
        human_review_threshold: Risk level that triggers human review (default: 0.9).
        auto_approve_low_risk: Auto-approve if risk < this value (default: 0.3).
    """
    
    def __init__(
        self,
        max_risk_threshold: float = 0.8,
        min_confidence_threshold: float = 0.6,
        require_explicit_approval: bool = False,
        human_review_threshold: float = 0.9,
        auto_approve_low_risk: float = 0.3,
    ):
        self.max_risk_threshold = max_risk_threshold
        self.min_confidence_threshold = min_confidence_threshold
        self.require_explicit_approval = require_explicit_approval
        self.human_review_threshold = human_review_threshold
        self.auto_approve_low_risk = auto_approve_low_risk


def create_verification_node(
    node_name: str,
    target_node: str,
    config: VerificationConfig = None,
    custom_validators: list = None,
):
    """Factory function to create a verification node for a high-risk operation.
    
    This creates a verification node that MUST approve before the target_node
    can execute. The verification node performs safety checks based on:
    - Risk level assessment
    - Confidence thresholds
    - Custom domain-specific validators
    - Human review requirements
    
    Args:
        node_name: Name for the verification node (e.g., "verify_trade").
        target_node: The high-risk node this verifies (e.g., "execute_trade").
        config: Verification configuration. Uses defaults if not provided.
        custom_validators: List of custom validation functions.
        
    Returns:
        A verification node function decorated with NormativeCore.VERIFY.
        
    Example:
        >>> verify_trade = create_verification_node(
        ...     node_name="verify_trade",
        ...     target_node="execute_trade",
        ...     config=VerificationConfig(max_risk_threshold=0.7)
        ... )
        >>> # Add to graph: graph.add_node("verify_trade", verify_trade)
        >>> # Add edge: graph.add_edge("analyze", "verify_trade")
        >>> # Add conditional: graph.add_conditional_edges("verify_trade", ...)
    """
    if config is None:
        config = VerificationConfig()
    
    if custom_validators is None:
        custom_validators = []
    
    def verify_node(state: Dict[str, Any]) -> Dict[str, Any]:
        """Verification node that validates before high-risk operations.
        
        Args:
            state: Current workflow state.
            
        Returns:
            Updated state with verification results.
        """
        logger.info(f"[{node_name}] Starting verification for {target_node}")
        
        # Extract relevant fields from state
        confidence = state.get("confidence", 0.5)
        risk_level = state.get("risk_level", 0.5)
        
        validation_errors = []
        
        # === RISK LEVEL CHECK ===
        if risk_level > config.max_risk_threshold:
            validation_errors.append(
                f"Risk level {risk_level:.2f} exceeds maximum threshold {config.max_risk_threshold}"
            )
            logger.warning(f"[{node_name}] High risk detected: {risk_level}")
        
        # === CONFIDENCE CHECK ===
        if confidence < config.min_confidence_threshold:
            validation_errors.append(
                f"Confidence {confidence:.2f} below minimum threshold {config.min_confidence_threshold}"
            )
            logger.warning(f"[{node_name}] Low confidence detected: {confidence}")
        
        # === CUSTOM VALIDATORS ===
        for validator in custom_validators:
            try:
                validator_result = validator(state)
                if not validator_result.get("valid", True):
                    validation_errors.append(validator_result.get("error", "Custom validation failed"))
            except Exception as e:
                validation_errors.append(f"Validator error: {str(e)}")
        
        # === DETERMINE APPROVAL ===
        requires_human_review = (
            risk_level > config.human_review_threshold or
            len(validation_errors) > 2
        )
        
        # Auto-approve low-risk, high-confidence operations
        auto_approved = (
            risk_level < config.auto_approve_low_risk and
            confidence > config.min_confidence_threshold and
            len(validation_errors) == 0
        )
        
        # Final approval decision
        approved = (
            auto_approved or
            (len(validation_errors) == 0 and not requires_human_review)
        )
        
        # Build result
        result = VerificationResult(
            approved=approved,
            confidence=confidence,
            risk_level=risk_level,
            reason="; ".join(validation_errors) if validation_errors else "All checks passed",
            requires_human_review=requires_human_review,
            validation_errors=validation_errors,
        )
        
        # Log decision
        if approved:
            logger.info(f"[{node_name}] APPROVED: {result.reason}")
        else:
            logger.warning(f"[{node_name}] BLOCKED: {result.reason}")
        
        # Return updated state
        return {
            **state,
            **result.to_dict(),
            f"{node_name}_complete": True,
        }
    
    # Store metadata for graph building
    verify_node.__verification_metadata__ = {
        "node_name": node_name,
        "target_node": target_node,
        "config": config,
    }
    
    return verify_node


def create_verification_router(approved_target: str, rejected_target: str):
    """Create a routing function for verification decisions.
    
    This creates a router that checks verification results and routes
    to either the approved path or rejected path.
    
    Args:
        approved_target: Node to route to when verification passes.
        rejected_target: Node to route to when verification fails (e.g., "human_review", "retry").
        
    Returns:
        A routing function for use with graph.add_conditional_edges().
        
    Example:
        >>> router = create_verification_router(
        ...     approved_target="execute_trade",
        ...     rejected_target="human_review"
        ... )
        >>> graph.add_conditional_edges("verify_trade", router)
    """
    def route_verification(state: Dict[str, Any]) -> str:
        """Route based on verification results."""
        verified = state.get("verified", False)
        requires_human_review = state.get("requires_human_review", False)
        
        if requires_human_review:
            logger.info(f"Routing to human review (requires_human_review=True)")
            return rejected_target
        
        if verified:
            logger.info(f"Verification passed, routing to {approved_target}")
            return approved_target
        else:
            logger.warning(f"Verification failed, routing to {rejected_target}")
            return rejected_target
    
    return route_verification


{% for high_risk_node in high_risk_nodes %}
# =============================================================================
# Verification for: {{ high_risk_node.function_name }}
# =============================================================================

# Configuration for {{ high_risk_node.function_name }} verification
{{ high_risk_node.function_name }}_verification_config = VerificationConfig(
    max_risk_threshold={{ high_risk_node.max_risk_threshold | default(0.8) }},
    min_confidence_threshold={{ high_risk_node.min_confidence_threshold | default(0.6) }},
    require_explicit_approval={{ high_risk_node.require_explicit_approval | default(false) | lower }},
    human_review_threshold={{ high_risk_node.human_review_threshold | default(0.9) }},
    auto_approve_low_risk={{ high_risk_node.auto_approve_low_risk | default(0.3) }},
)

# Create verification node
verify_{{ high_risk_node.function_name }} = create_verification_node(
    node_name="verify_{{ high_risk_node.function_name }}",
    target_node="{{ high_risk_node.function_name }}",
    config={{ high_risk_node.function_name }}_verification_config,
)

# Create verification router
route_{{ high_risk_node.function_name }}_verification = create_verification_router(
    approved_target="{{ high_risk_node.function_name }}",
    rejected_target="{{ high_risk_node.rejected_target | default('human_review') }}",
)

{% endfor %}

# =============================================================================
# Human Review Node (Fallback for rejected verifications)
# =============================================================================

def human_review_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """Fallback node for operations requiring human review.
    
    This node is routed to when:
    - Verification fails and operation is too risky to proceed
    - Risk level exceeds human_review_threshold
    - Multiple validation errors detected
    
    In production, this would:
    - Send notification to human operators
    - Log the pending review
    - Set state to await human decision
    
    Args:
        state: Current workflow state with verification failures.
        
    Returns:
        Updated state with human_review_pending flag.
    """
    logger.warning("[human_review] Operation routed for human review")
    
    validation_errors = state.get("validation_errors", [])
    risk_level = state.get("verification_risk_level", "unknown")
    reason = state.get("verification_reason", "No reason provided")
    
    logger.warning(f"[human_review] Reason: {reason}")
    logger.warning(f"[human_review] Risk Level: {risk_level}")
    logger.warning(f"[human_review] Validation Errors: {validation_errors}")
    
    return {
        **state,
        "human_review_pending": True,
        "human_review_reason": reason,
        "human_review_timestamp": __import__("datetime").datetime.now().isoformat(),
    }


# =============================================================================
# Integration Utilities
# =============================================================================

def inject_verification_into_graph(
    graph,
    high_risk_node: str,
    verification_node_fn,
    verification_router_fn,
    predecessor_node: str,
):
    """Inject verification step between predecessor and high-risk node.
    
    This modifies the graph to insert a verification node:
    BEFORE: predecessor -> high_risk_node
    AFTER:  predecessor -> verify_node -> (approved: high_risk_node, rejected: human_review)
    
    Args:
        graph: The StateGraph instance to modify.
        high_risk_node: Name of the high-risk node requiring verification.
        verification_node_fn: The verification node function.
        verification_router_fn: The verification routing function.
        predecessor_node: Node that should route to verification instead of high-risk.
        
    Example:
        >>> inject_verification_into_graph(
        ...     graph=workflow,
        ...     high_risk_node="execute_trade",
        ...     verification_node_fn=verify_execute_trade,
        ...     verification_router_fn=route_execute_trade_verification,
        ...     predecessor_node="analyze_trade"
        ... )
    """
    verify_node_name = f"verify_{high_risk_node}"
    
    # Add verification node
    graph.add_node(verify_node_name, verification_node_fn)
    
    # Add human review node if not present
    if "human_review" not in graph.nodes:
        graph.add_node("human_review", human_review_node)
    
    # Add conditional edges from verification
    graph.add_conditional_edges(
        verify_node_name,
        verification_router_fn,
        {
            high_risk_node: high_risk_node,
            "human_review": "human_review",
        }
    )
    
    logger.info(
        f"Injected verification: {predecessor_node} -> {verify_node_name} -> "
        f"(approved: {high_risk_node}, rejected: human_review)"
    )
